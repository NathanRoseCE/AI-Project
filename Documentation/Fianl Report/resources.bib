@online{NEAT,
    author = "Wikipedia",
    title = "Neuroevolution of augmenting topologies",
    url  = "https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies",
    addendum = "(accessed: 02.22.2022)",
    keywords = "NEAT, AI",
    year={2021}
}

@online{TexasHoldEm,
    author =  "Wikipedia, 16-Feb-2022",
    title = "Texas hold'em",
    url = "https://en.wikipedia.org/wiki/Texas_hold_\%27em",
    addendum = "(Accessed: 23-Feb-2022)", 
    keywords = "Texas hold'em, Poker",
    year = {2021}
}

@inproceedings{brown2017libratus,
  title={Libratus: The Superhuman AI for No-Limit Poker.},
  author={Brown, Noam and Sandholm, Tuomas and Machine, Strategic},
  booktitle={IJCAI},
  pages={5226--5228},
  year={2017}
}

@inproceedings{davidson2000improved,
  title={Improved opponent modeling in poker},
  author={Davidson, Aaron and Billings, Darse and Schaeffer, Jonathan and Szafron, Duane},
  booktitle={International Conference on Artificial Intelligence, ICAI’00},
  pages={1467--1473},
  year={2000}
}

@inproceedings{gilpin2005optimal,
  title={Optimal Rhode Island hold'em poker},
  author={Gilpin, Andrew and Sandholm, Tuomas},
  booktitle={PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE},
  volume={20},
  number={4},
  pages={1684},
  year={2005},
  organization={Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999}
}

@inproceedings{gilpin2006competitive,
  title={A competitive Texas Hold'em poker player via automated abstraction and real-time equilibrium computation},
  author={Gilpin, Andrew and Sandholm, Tuomas},
  booktitle={AAAI},
  pages={1007--1013},
  year={2006}
}

@article{
doi:10.1126/science.aay2400,
author = {Noam Brown  and Tuomas Sandholm },
title = {Superhuman AI for multiplayer poker},
journal = {Science},
volume = {365},
number = {6456},
pages = {885-890},
year = {2019},
doi = {10.1126/science.aay2400},
URL = {https://www.science.org/doi/abs/10.1126/science.aay2400},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aay2400},
abstract = {Computer programs have shown superiority over humans in two-player games such as chess, Go, and heads-up, no-limit Texas hold'em poker. However, poker games usually include six players—a much trickier challenge for artificial intelligence than the two-player variant. Brown and Sandholm developed a program, dubbed Pluribus, that learned how to play six-player no-limit Texas hold'em by playing against five copies of itself (see the Perspective by Blair and Saffidine). When pitted against five elite professional poker players, or with five copies of Pluribus playing against one professional, the computer performed significantly better than humans over the course of 10,000 hands of poker. Science, this issue p. 885; see also p. 864 An AI dubbed Pluribus performs significantly better than human professionals in six-player no-limit Texas hold’em poker. In recent years there have been great strides in artificial intelligence (AI), with games often serving as challenge problems, benchmarks, and milestones for progress. Poker has served for decades as such a challenge problem. Past successes in such benchmarks, including poker, have been limited to two-player games. However, poker in particular is traditionally played with more than two players. Multiplayer games present fundamental additional issues beyond those in two-player games, and multiplayer poker is a recognized AI milestone. In this paper we present Pluribus, an AI that we show is stronger than top human professionals in six-player no-limit Texas hold’em poker, the most popular form of poker played by humans.}}
